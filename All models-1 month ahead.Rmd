---
title: "All forecasting models-one month ahead"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



Forecasting one month ahead. Models are BRNN with LSTM layer, SVR WITH (ANOVA RBF kernel), and SBC with Fuzzy C-mean.

Libraries
```{r}
library(readxl)
library(tibble)
library(readr)
library(ggplot2)
library(keras)
library(tensorflow)
library(Metrics)
library(frbs)
library(kernlab)
library(rmarkdown)
```
BRNN model generator function, 

data — The original array of floating-point data, which is normalized

lookback — How many timesteps back the input data should go.

delay — How many timesteps in the future the target should be.

min_index and max_index — Indices in the data array that delimit which timesteps to draw from. This is useful for keeping a segment of the data for validation and another for testing.

shuffle — Whether to shuffle the samples or draw them in chronological order.

batch_size — The number of samples per batch.

step — The period, in timesteps, at which sample data. It set 1 in order to draw one data point every minute.

```{r}
generator <- function(data,
                      lookback,
                      delay,
                      min_index,
                      max_index,
                      shuffle = FALSE,
                      batch_size = 128,
                      step = 1) {
    if (is.null(max_index))
        max_index <- nrow(data) - delay - 1
    i <- min_index + lookback
    function() {
        if (shuffle) {
            rows <-
                sample(c((min_index + lookback):max_index), size = batch_size)
        } else {
            if (i + batch_size >= max_index)
                i <<- min_index + lookback
            rows <- c(i:min(i + batch_size - 1, max_index))
            i <<- i + length(rows)
        }
        samples <- array(0, dim = c(length(rows),
                                    lookback / step,
                                    dim(data)[[-1]]))
        targets <- array(0, dim = c(length(rows)))
        
        for (j in 1:length(rows)) {
            indices <- seq(rows[[j]] - lookback, rows[[j]] - 1,
                           length.out = dim(samples)[[2]])
            samples[j, , ] <- data[indices, ]
            targets[[j]] <- data[rows[[j]] + delay, 9]
        }
        list(samples, targets)
    }
}

```

Entering original data, data scaling and [0,1] min-max normalization
8000 consecutive random rows of data by sampling 10 is selected from the main data set(starting point is random)
after each time of code execution, a different part of the data set will be selected
average of the RMSE and MAE of 10 times run calculated as result.


```{r}
fname <- file.path("C:/Users/nemes/Desktop/dataset.xlsx")
raw_data <- read_xlsx(fname)

N=258246
n=80000
sys = function(N,n){
    r = sample(1:(N-n), 1)
    seq(r, ((r + 80000) -1), 10)         #selecting 2 months consecutive random data set
}
sys_sample<-raw_data[sys(nrow(raw_data), 80000), ]

data <- data.matrix(sys_sample[1:8000, -1])

mean <- apply(data, 2, mean)
std <- apply(data, 2, sd)
data <- scale(data, center = mean, scale = std)

normalize <- function(x) {
    return ((x - min(x)) / (max(x) - min(x)))}

max <- apply(data,2,max)
min <- apply(data,2,min)

data2 <- apply(data, 2, normalize)

is.nan.data.frame <- function(x)
    do.call(cbind, lapply(x, is.nan))
data2[is.nan(data2)] <- 0 #if there is any NaN value in the data change it to zero

data2 = data2[, colSums(data2 != 0) > 0] #if there is any column with all zero value omit the column


write.csv(sys_sample, 'data-tenthrun-1month.csv')
```

data preparation for our BRNN model
2000 assigned to training set and 2000 to verification data

```{r}
lookback <- 1
step <- 1
batch_size <- 4000

train_gen <- generator(
    data2,
    lookback = lookback,
    delay = 0,
    min_index = 1,
    max_index = 2000,
    shuffle = FALSE,
    step = step,
    batch_size = batch_size)

val_gen <- generator(
    data2,
    lookback = lookback,
    delay = 0,
    min_index = 2001,
    max_index = 4000,
    shuffle = FALSE,
    step = step,
    batch_size = batch_size)

train_gen_data <- train_gen()
val_gen_data <- val_gen()
```

Data preparation for SVR and SBC models, also preparing real values of foretasted output to evaluate our models later, the ninth column is the output 

```{r}
data.train <- matrix(data2[1 : 4000, ],ncol = 9, byrow = FALSE)
colnames(data.train) <- c("inp.1","inp.2","inp.3","inp.4","inp.5","inp.6","inp.7","inp.8", "out.1")
data.fit <- data.train[, -ncol(data.train)] # just include input variables of training set
data.tst <- matrix(data2[4001:8000, 1 : 8 ],ncol = 8, byrow = FALSE)
x <- data.train[, -ncol(data.train)]
y <- data.train[,9]

real.val.SVM <- matrix(data2[4001:8000, 9], ncol = 1)
real.val.SBC <- matrix(data2[4001:8000, 9], ncol = 1)
real.val.ANN <- matrix(data2[4001:8000, 9], ncol = 1)

range.data <- matrix(apply(data.train, 2, range), nrow = 2)
```

Building bidirectional recurrent NN model with one LSTM layer, 2 dense layers, and Hyperbolic Tangent activation function 
 

```{r}
Model.BRNN <- keras_model_sequential() %>%
    bidirectional(
                   layer_lstm(units = 128),input_shape = list(NULL,                                           dim(data2)[[-1]])) %>% 
    layer_dense(units = 64, activation = "tanh") %>%
    layer_dense(units = 1, activation = "tanh")


Model.BRNN %>% compile(optimizer = optimizer_rmsprop(),
                  loss = "mae")

summary(Model.BRNN)

callbacks = callback_early_stopping(monitor = "val_loss", min_delta = 0,
                                    patience = 30, verbose = 0, mode = "auto",
                                    baseline = NULL, restore_best_weights = TRUE) # preserving our current model

```

Fitting our model with 50 epochs and validation step size 1.

```{r}

history <- Model.BRNN %>% fit(
    train_gen_data[[1]],train_gen_data[[2]],
    batch_size = 64,
    epochs = 50,
    callbacks = callbacks,
    validation_data = val_gen_data,
    validation_steps = 1) 
```

Forecasting with the test set and plot the result (Bidirectional LSTM)

```{r}
batch_size_plot <- 4000
lookback_plot <- 1
step_plot <- 1

pred_gen <- generator(
    data2,
    lookback = lookback_plot,
    delay = 0,
    min_index = 4000,
    max_index = 8000,
    shuffle = FALSE,
    step = step_plot,
    batch_size = batch_size_plot
)

pred_gen_data <- pred_gen()

V1 = seq(1, length(pred_gen_data[[2]]))

plot_data <-
    as.data.frame(cbind(V1, pred_gen_data[[2]]))

inputdata <- pred_gen_data[[1]][, , ]
dim(inputdata) <- c(batch_size_plot, lookback_plot, 9)

pred_out <- Model.BRNN %>%
    predict(inputdata)

plot_data <-
    cbind(plot_data, pred_out[])

p <-
    ggplot(plot_data, aes(x = V1, y = V2)) + geom_line(colour = "red",
                                                        size = 1,
                                                        alpha = 4 )+labs(y= "Normalized real and predicted values on the interval [0,1]", x = "1 month ahead")+ggtitle("Real.Values (red) Vs Predicted.Values (blue)")
p <-
    p + geom_line(
        aes(x = V1, y = pred_out),
        colour = "blue",
        size = 1 ,
        alpha = 4
    )
p+theme(axis.text=element_text(size=35),
        axis.title=element_text(size=35,face="bold"),
        plot.title=element_text(size=37,face="bold",hjust = 0.5),
        axis.title.y = element_text(margin = margin(t = 20, r = 20, b = 20, l = 20)))

p
```

Evaluation BRNN by MAE and RMSE

```{r}
error.ANN= real.val.ANN -pred_out


mae.ANN <- function(error.ANN)
{
    mean(abs(error.ANN))
}
mae.ANN = mae.ANN(error.ANN)

bench.ann <- cbind(pred_out, real.val.ANN)
colnames(bench.ann) <- c("pred. val.", "real. val.")


# print(bench)


RMSE.ANN <- sqrt(mean(error.ANN^2))

variance.ANN = var(error.ANN)

```

Building the model SVR with ANOVA RBF kernel with epsilon = 0.1 with the default parameters

```{r}
modelsvm <- ksvm(x,y,type = "eps-svr", epsilon=0.1, kernel="anovadot", kpar=list(sigma=1,degree = 1)) 
svm.fit = predict(modelsvm, newdata= x)
predYsvm = predict(modelsvm, newdata= data.tst)

```

Model evaluation of SVR (MAE, RMSE)

```{r}
error.SVM = real.val.SVM - predYsvm
#error

mae.SVM <- function(error.SVM)
{
    mean(abs(error.SVM))
}
mae.SVM = mae.SVM(error.SVM)

RMSE.SVM =rmse(predYsvm,real.val.SVM )

variance.svm = var(error.SVM)
```

Plot the result of SVR model

```{r}
result.test.svm <- cbind(real.val.SVM , predYsvm)

X <- seq(from = 1, to = nrow(result.test.svm ))

p1 <-
    ggplot(plot_data, aes(x = X, y = result.test.svm[, 1])) + geom_line(colour = "red",
                                                       size = 1,
                                                       alpha = 4 )+labs(y= "Normalized real and predicted values on the interval [0,1]", x = "10 minutes ahead")+ggtitle("Real.Values (red) Vs Predicted.Values (blue)")
p1 <-
    p1 + geom_line(
        aes(x = X, y = result.test.svm[, 2]),
        colour = "blue",
        size = 1 ,
        alpha = 4
    )

p1+theme(axis.text=element_text(size=35),
        axis.title=element_text(size=35,face="bold"),
        plot.title=element_text(size=37,face="bold",hjust = 0.5),
        axis.title.y = element_text(margin = margin(t = 20, r = 20, b = 20, l = 20)))
p1
```

Fuzzy clustering model (SBC) with C-mean optimization with cluster ratio 0.3
 

```{r}
method.type <- "SBC"
control.SBC <- list(r.a = 0.3, eps.high = 0.5, eps.low = 0.15, name = "Sim-0")


object.SBC <- frbs.learn(data.train, range.data, method.type, control.SBC)

res.fit <- predict(object.SBC , data.fit)
res.test <- predict(object.SBC , data.tst)
```

MOdel SBC evaluation(MAE, RMSE)

```{r}
y.pred <- res.test
y.real <- real.val.SBC

bench.SBC <- cbind(y.pred, y.real)

colnames(bench.SBC) <- c("pred. val.", "real. val.")

error.SBC = y.real - y.pred

mae.SBC <- function(error.SBC)
{
  mean(abs(error.SBC))
}

mae.SBC = mae.SBC(error.SBC)

#print(bench.SBC)

residuals <- (y.real - y.pred)

RMSE.SBC <- sqrt(mean(residuals^2))

variance.sbc = var(error.SBC)
```

plot the resaults of model SBC

```{r}

result.test.sbc <- cbind(y.real, y.pred)

x1 <- seq(from = 1, to = nrow(result.test.sbc))

p2 <-
    ggplot(plot_data, aes(x = x1, y = result.test.sbc[, 1])) + geom_line(colour = "red",
                                                       size = 1,
                                                       alpha = 4 )+labs(y= "Normalized real and predicted values on the interval [0,1]", x = "10 minutes ahead")+ggtitle("Real.Values (red) Vs Predicted.Values (blue)")
p2 <-
    p2 + geom_line(
        aes(x = x1, y = result.test.sbc[, 2]),
        colour = "blue",
        size = 1 ,
        alpha = 4
    )
p2+theme(axis.text=element_text(size=35),
        axis.title=element_text(size=35,face="bold"),
        plot.title=element_text(size=37,face="bold",hjust = 0.5),
        axis.title.y = element_text(margin = margin(t = 20, r = 20, b = 20, l = 20)))
p2
```


